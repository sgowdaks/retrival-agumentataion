{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import http.client, urllib.parse\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_metric\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirement \n",
    "# torch                    2.1.2\n",
    "# pandas                   2.1.4'\n",
    "# numpy                    1.26.3\n",
    "# faiss-gpu                1.7.2\n",
    "# transformers             4.36.2\n",
    "# fastparquet              2023.10.1\n",
    "#datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = \"df1c1027bc3dd38b6cddb5e53a1ec1da\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "model_id = \"mistralai/mistral-7b-instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  3.33s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `device` and `device_map` are specified. `device` will override `device_map`. You will most likely encounter unexpected behavior. Please remove `device` and keep `device_map`.\n"
     ]
    }
   ],
   "source": [
    "hf_pipeline = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model.eval(),\n",
    "            tokenizer=tokenizer,\n",
    "            use_cache=True,\n",
    "            max_new_tokens=1000,\n",
    "            top_k=10,\n",
    "            top_p=0.95,\n",
    "            typical_p=0.95,\n",
    "            do_sample=True,\n",
    "            temperature=0.1,\n",
    "            repetition_penalty=1.03,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            device_map=\"auto\",\n",
    "            device=\"cuda\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = http.client.HTTPConnection('api.mediastack.com')\n",
    "\n",
    "params = urllib.parse.urlencode({\n",
    "    'access_key': access_key,\n",
    "    'categories': '-general,-sports',\n",
    "    'sort': 'published_desc',\n",
    "    'limit': 10,\n",
    "    'countries': 'us'\n",
    "    })\n",
    "\n",
    "conn.request('GET', '/v1/news?{}'.format(params))\n",
    "\n",
    "res = conn.getresponse()\n",
    "data = res.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.decode('utf-8')\n",
    "data = json.loads(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': None,\n",
       " 'title': 'DWS Strategic Municipal Income Trust declares $0.026 dividend',\n",
       " 'description': 'DWS Strategic Municipal Income Trust declares $0.026 dividend',\n",
       " 'url': 'https://seekingalpha.com/news/4054359-dws-strategic-municipal-income-trust-declares-0026-dividend?utm_source=feed_news_all&utm_medium=referral&feed_item_type=news',\n",
       " 'source': 'Seeking Alpha',\n",
       " 'image': None,\n",
       " 'category': 'business',\n",
       " 'language': 'en',\n",
       " 'country': 'us',\n",
       " 'published_at': '2024-01-11T14:16:39+00:00'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_index = \"data/knn.index\"\n",
    "wiki_en = \"data/wikipedia-en.parquet\"  \n",
    "wiki_en_sentences = \"data/wikipedia-en-sentences.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below code is adapted from the project openchatkit(https://github.com/togethercomputer/OpenChatKit) retrival agumentataion,\n",
    "\n",
    "def mean_pooling(token_embeddings, mask):\n",
    "    token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
    "    sentence_embeddings = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "    return sentence_embeddings\n",
    "\n",
    "def cos_sim_2d(x, y):\n",
    "    norm_x = x / np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    norm_y = y / np.linalg.norm(y, axis=1, keepdims=True)\n",
    "    return np.matmul(norm_x, norm_y.T)\n",
    "\n",
    "\n",
    "class WikipediaIndex:\n",
    "    def __init__(self):\n",
    "        indexpath = knn_index\n",
    "        wiki_sentence_path = wiki_en_sentences\n",
    "\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained('facebook/contriever-msmarco')\n",
    "        self._contriever = AutoModel.from_pretrained('facebook/contriever-msmarco').to(device)\n",
    "\n",
    "        self._df_sentences = pd.read_parquet(wiki_sentence_path, engine='fastparquet')\n",
    "\n",
    "        self._wiki_index = faiss.read_index(indexpath, faiss.IO_FLAG_MMAP | faiss.IO_FLAG_READ_ONLY)\n",
    "\n",
    "\n",
    "    def search(self, query, k=1, w=5, w_th=0.5):\n",
    "        inputs = self._tokenizer(query, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        outputs = self._contriever(**inputs)\n",
    "        embeddings = mean_pooling(outputs[0], inputs['attention_mask'])\n",
    "        \n",
    "        query_vector = embeddings.cpu().detach().numpy().reshape(1, -1)\n",
    "        \n",
    "        distances, indices = self._wiki_index.search(query_vector, k)  \n",
    "\n",
    "        try:\n",
    "            input_texts = self._df_sentences.iloc[indices[0]]['text_snippet'].values[0]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "                    \n",
    "        return input_texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:  DWS Strategic Municipal Income Trust declares $0.026 dividend\n",
      "description:  DWS Strategic Municipal Income Trust declares $0.026 dividend\n",
      "answer:  answer: The DWS Strategic Municipal Income Trust declared a final liquidating dividend of $0.026 per share, with a liquidating value of $46.34 per share. The remaining cash of $4,045,358 was distributed pro rata among the stockholders.\n"
     ]
    }
   ],
   "source": [
    "wp = WikipediaIndex()\n",
    "\n",
    "for article in articles:\n",
    "    title = article['title']\n",
    "    description = article['description']\n",
    "    context = wp.search(title)\n",
    "    prompt = \"[INST] Give this description: \" + description + \" and this context: \"+ context  + \": enhance the description with the provided context and generate a meanigful sentence [/INST] answer:\"\n",
    "    answer = hf_pipeline(prompt)\n",
    "    print(\"title: \",  title)\n",
    "    print(\"description: \", description)\n",
    "    num = answer[0]['generated_text'].find(\"answer:\")\n",
    "    answer = answer[0]['generated_text'][num:]\n",
    "    print(\"answer: \", answer)\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45933/4162985767.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"bleu\")\n",
      "/home/sg/miniconda3/envs/myenv/lib/python3.9/site-packages/datasets/load.py:752: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/bleu/bleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 6.06kB [00:00, 5.04MB/s]                   \n",
      "Downloading extra modules: 4.07kB [00:00, 3.98MB/s]                   \n",
      "config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.72k/1.72k [00:00<00:00, 128kB/s]\n",
      "vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 899k/899k [00:00<00:00, 3.36MB/s]\n",
      "merges.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 30.6MB/s]\n",
      "tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.36M/1.36M [00:00<00:00, 4.20MB/s]\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"bleu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "generated_tokens = tokenizer(answer, return_tensors=\"pt\")\n",
    "reference_tokens = tokenizer(description, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 27740,    35,    20,   211, 13691, 14152, 11660,  9628,  3101,\n",
       "          2998,    10,   507,  6936,  1295,  2252,     9,    68,   288,     4,\n",
       "         40521,   228,   458,     6,    19,    10,  6936,  1295,   923,     9,\n",
       "            68,  3761,     4,  3079,   228,   458,     4,    20,  2405,  1055,\n",
       "             9,    68,   306,     6, 39664,     6, 34392,    21,  7664,  1759,\n",
       "           910,  2186,   566,     5,   388,  7509,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = metric.compute(predictions=[generated_tokens.input_ids], references=[reference_tokens.input_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0,\n",
       " 'precisions': [0.0, 0.0, 0.0, 0.0],\n",
       " 'brevity_penalty': 2.2603294069810542e-06,\n",
       " 'length_ratio': 0.07142857142857142,\n",
       " 'translation_length': 1,\n",
       " 'reference_length': 14}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
